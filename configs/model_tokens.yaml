# Model Token Configuration

# This file contains the pre-configured target tokens and last tokens for different models.
# These tokens are used to trigger the deadlock behavior.

models:
  DeepSeek-R1-Distill-Qwen-7B:
    target_tokens:
      - [14190, 3983]  # 'Wait', 'But'
      - [13824, 1988]  # ' Wait', ' But'
    last_tokens:
      - [382, 271, 3593, 692, 1939]
      - [13, 568, 30]
    
  DeepSeek-R1-Distill-Llama-8B:
    target_tokens:
      - [14524, 4071]  # 'Wait', 'But'
      - [14144, 2030]  # ' Wait', ' But'
    last_tokens:
      - [382, 271, 3677, 696, 1980]
      - [13, 570, 30]
    
  Llama-3.1-Nemotron-Nano-8B-v1:
    target_tokens:
      - [14524, 4071]  # 'Wait', 'But'
      - [14144, 2030]  # ' Wait', ' But'
    last_tokens:
      - [382, 271, 3677, 696, 1980]
      - [13, 570, 30]
    
  Phi-4-mini-reasoning:
    target_tokens:
      - [17114, 7943]  # 'Wait', 'But'
      - [24305, 3072]  # ' Wait', ' But'
    last_tokens:
      - [364, 279, 3991, 1029, 1715]
      - [13, 741, 30]
